[
  {
    "Filter": {
      "Regions": [
        "USGovTexas",
        "USGovVirginia"
      ]
    },
    "Name": "Gov Messaging Timeout",
    "Description": "Please refer to the SOP in https://info.citrite.net/display/CWC/Alert+SOP+-+Messaging+Timeout.",
    "Type": "Splunk",
    "Properties": {
      "Search": "ServiceName=Messaging LoggingType=Performance \n| bin _time span=5m \n| rex field=_raw \"\"StatusCode\":\"(?<apiStatus>[a-zA-Z0-9:/\\.]+)\"\" \n| stats count(eval(apiStatus==\"RequestTimeout\")) as RequestTimeoutCount,Count as TotalCount, by_time,source,RoleId \n| eval CriticalErrorPercentage=20 \n| where ((RequestTimeoutCount)/(TotalCount)*100) > CriticalErrorPercentage",
      "Disabled": false,
      "Indices": [
        "productiongov_cc_services"
      ],
      "Sources": [
        "*"
      ],
      "Emails": [
        "workspaceadmins@citrix.com",
        "bradley.rowe@citrix.com",
        "amit.shah@citrix.com",
        "xiaojie.yu@citrix.com",
        "leandro.taset@citrix.com"
      ],
      "SlackChannel": {
        "Channel": "#cc-apollo-alerts",
        "Message": "*PRODUCTION GOV- \"Messaging Timeout\"\n>*Time* : $result._Time$\n>*Source* : $result.source$\n>*Fail Count*: $result.count$"
      },
      "PagerDuty": "https://events.pagerduty.com/integration/a6479c7a2ce24497b7155138378f46f9/enqueue",
      "CronExpression": "*/10 * * * *",
      "StartTime": "-15m",
      "EndTime": "now",
      "AlertWhenGreaterThan": "0"
    }
  },
  {
    "Filter": {
      "Regions": [
        "USGovTexas",
        "USGovVirginia"
      ]
    },
    "Name": "Redis Connection Exception",
    "Description": "Redis connectivity issues that have proven to cause issues with messaging service. SOP: https://info.citrite.net/display/CWC/Redis+Connection+Exception",
    "Type": "Splunk",
    "Properties": {
      "Search": "StackExchange.Redis.RedisConnectionException | bucket _time span=30s | stats count by _time | where count > 0 | eventstats dc(_time) as RepeatationCount | where RepeatationCount > 1 | fields - RepeatationCount",
      "Disabled": false,
      "Indices": [
        "productiongov_cc_services"
      ],
      "Sources": [
        "cc/ProductionGov/USGovTexas/*/Cluster",
        "cc/ProductionGov/USGovVirginia/*/Cluster"
      ],
      "Emails": [
        "workspaceadmins@citrix.com"
      ],
      "SlackChannel": {
        "Channel": "#cc-apollo-alerts",
        "Message": "*Production - StackExchange.Redis.RedisConnectionException*\n>*Time* : $result.fTime$\n>*Instance* : $result.RoleId$\n>*Source* : $result.source$\n>*Exception* : $result.Exception$\n>*Fail Count*: $result.count$"
      },
      "CronExpression": "*/15 * * * *",
      "StartTime": "-15m",
      "EndTime": "now",
      "AlertWhenGreaterThan": "0"
    }
  },
  {
    "Filter": {
      "Regions": [
        "USGovTexas",
        "USGovVirginia"
      ]
    },
    "Name": "Potential Failover Scenario For Messaging Service",
    "Description": "Potential Failover Scenario For Messaging Service; see Splunk results for more information.\n\nSOP: https://info.citrite.net/x/Gd7qY",
    "Type": "Splunk",
    "Properties": {
      "SplitIndicesByRegionEnv": true,
      "Search": "ServiceName=Messaging \n EventType=Performance OR EventType=ApiPerformance \n | eval RequestUri = json_extract(Message, \"Uri\") \n | where NOT LIKE(RequestUri, \"%-direct-%\") AND NOT LIKE(RequestUri, \"%-asfdirect-%\") \n | rex field=source \".+\\/(?<LoggingLayer>.+)\\/(?<LoggingRegion>.+)\\/(?<release>.+)\\/\" \n | rex field=RequestUri \"\\/(?<RequestService>\\w+)-(?<RequestRegion>\\w+)-(?<RequestLayer>\\w+)-\" \n | where lower(LoggingRegion) != lower(RequestRegion) \n | stats count by ServiceName, source, LoggingRegion, RequestRegion \n | where count > 100",
      "Disabled": false,
      "Indices": [
        "productiongov_cc_services",
        "productiongov_cc_services"
      ],
      "Sources": [
        "cc/ProductionGov/USGovTexas/*/Cluster",
        "cc/ProductionGov/USGovVirginia/*/Cluster"
      ],
      "SlackChannel": {
        "Channel": "#cc-apollo-alerts",
        "Message": "PRODUCTION GOV: Potential failover scenario for $result.ServiceName$ in $result.RequestRegion$!\n\nThe service in $result.LoggingRegion$ handled $result.count$ requests originally meant for $result.RequestRegion$\n\nSee all results <$results_link$|here>. Alert generated from <$view_link$|$name$>"
      },
      "PagerDuty": "https://events.pagerduty.com/integration/a6479c7a2ce24497b7155138378f46f9/enqueue",
      "CronExpression": "6-59/15 * * * *",
      "StartTime": "-15m",
      "EndTime": "now",
      "AlertWhenGreaterThan": "0"
    }
  },
  {
    "Filter": {
      "Regions": [
        "USGovTexas",
        "USGovVirginia"
      ]
    },
    "Name": "Messaging health check failure",
    "Description": "Messaging health check failures were found. Check the dependency status by search ServiceName=Messaging CheckHealthAsync ",
    "Type": "Splunk",
    "Properties": {
      "Search": "CheckHealthAsync ServiceName=Messaging \n | eval minute=strftime(_time,\"%M\") \n | stats count by minute,source ",
      "SplitIndicesByRegionEnv": true,
      "Disabled": false,
      "Indices": [
        "productiongov_cc_services",
        "productiongov_cc_services"
      ],
      "Sources": [
        "cc/ProductionGov/USGovTexas/*/Cluster",
        "cc/ProductionGov/USGovVirginia/*/Cluster"
      ],
      "Emails": [
        "devin.michaels@citrix.com",
        "gaurav.gireesh@citrix.com",
        "jaganmohan.m@citrix.com",
        "james.kilts@citrix.com",
        "jorge.cifuentes@citrix.com",
        "michael.sun@citrix.com",
        "sowmya.nittala@citrix.com",
        "sudheer.bangera@citrix.com"
      ],
      "SlackChannel": {
        "Channel": "#cc-apollo-alerts",
        "Message": "PRODUCTION GOV: Messaging is experiencing a high count of health check failures in $result.source$, please be on alert for possible failover of Messaging service.\n\nSee Splunk results <$results_link$|here>. Alert generated from <$view_link$|$name$>"
      },
      "CronExpression": "*/15 * * * *",
      "StartTime": "-15m",
      "EndTime": "now",
      "AlertWhenGreaterThan": "2"
    }
  } 
]